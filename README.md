# CMPS 242 Machine Learning Project Code, Fall 2016 in UCSC
<p>
These are the implementations of several classfication algorithms in the Machine Learning course of UCSC.
</p>
<p>
word_dictionary_lr.py: The word dictionary generation python file for logistic regression, bayes logistic regression, KNN, decision tree and perceptron.   
</p>
<p>
word_dictionary.py: The word dictionary generation python file for naive bayes.  
</p>
preprocess_yelp_dataset.py: Generate the training dataset and test dataset.  
</p>
<p>
naive_bayes.py: Naive bayes classification python file and get the classification accuracy of training dataset and test dataset.  
</p>
<p>
<b>Perceptron:</b>
</p>
<p>
1. Run the preprocess_yelp_dataset.py to generate the training dataset and test dataset. 
</p>
<p>
2. Run the word_dictionary_lr.py to generate positive words dictionary and negtive words dictionary.
</p>
<p>
3. Run the perception.py to get the classication accuracy of training dataset and test dataset. 
</p>
<p>
<b>Naive Bayes:</b>
</p>
<p>
1. Run the preprocess_yelp_dataset.py to generate the training dataset and test dataset. 
</p>
<p>
2. Run the word_dictionary.py to generate positive words dictionary and negtive words dictionary.
</p>
<p>
3. Run the naive_bayes.py to get the classication accuracy of training dataset and test dataset. The performances of them are as following:
</p>
<p>
<b>Decision Tree:</b>
</p>
<p>
1. Run the preprocess_yelp_dataset.py to generate the training dataset and test dataset. 
</p>
<p>
2.Run the word_dictionary_lr.py to generate feature dictionary.
</p>
<p>
3.Run the decision_tree.py to train the decision tree and use the tree to get the classication accuracy of test dataset.                   
</p>
<p>
The decision feature we used :['great', 'good', 'like', 'just', 'get', 'food', 'one', 'place']
</p>
<p>
<b>KNN:</b>
</p>
<p>
1. Run the preprocess_yelp_dataset.py to generate the training dataset and test dataset. 
</p>
<p>
2.Run the word_dictionary_lr.py to generate feature dictionary.
</p>
<p>
3.Run the KNN.py to train the decision tree and use the tree to get the classication accuracy of test dataset.   
</p>
<p>
The decision feature we used :['a', 'and', 'the', 'i', 'to']
</p>
<b>Logistic Regression:</b>
</p>
<p>
1. Run the preprocess_yelp_dataset.py to generate the training dataset and test dataset. 
</p>
<p>
2.Run the word_dictionary_lr.py to generate feature dictionary.
</p>
<p>
3.Run the logisticregression.py to train the decision tree and use the tree to get the classication accuracy of test dataset.The proformance of the decision tree is as following:                    
</p>
<p>
The decision feature we used :['great', 'good', 'like', 'just', 'get', 'food', 'one', 'place']
</p>
<b>Bayes Logistic Regression:</b>
</p>
<p>
1. Run the preprocess_yelp_dataset.py to generate the training dataset and test dataset. 
</p>
<p>
2.Run the word_dictionary_lr.py to generate feature dictionary.
</p>
<p>
3.Run the bayes_logisticregressio.py to train the decision tree and use the tree to get the classication accuracy of test dataset.The proformance of the decision tree is as following:                    
</p>
<p>
The decision feature we used :['great', 'good', 'like', 'just', 'get', 'food', 'one', 'place']
</p>
